{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../derived/final_stats_data.csv\",low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'innings', 'overs', 'ballnumber', 'batter', 'bowler',\n",
       "       'non-striker', 'extra_type', 'batsman_run', 'extras_run', 'total_run',\n",
       "       'non_boundary', 'isWicketDelivery', 'player_out', 'kind',\n",
       "       'fielders_involved', 'BattingTeam', 'City', 'Date', 'Season',\n",
       "       'MatchNumber', 'Team1', 'Team2', 'Venue', 'TossWinner', 'TossDecision',\n",
       "       'SuperOver', 'WinningTeam', 'WonBy', 'Margin', 'method',\n",
       "       'Player_of_Match', 'Team1Players', 'Team2Players', 'Umpire1', 'Umpire2',\n",
       "       'BowlingTeam', 'batter_matches_played', 'runs_scored', 'dismissals',\n",
       "       'balls_faced', '0s_scored', '1s_scored', '2s_scored', '4s_scored',\n",
       "       '6s_scored', 'high_score', '25_scored', '50_scored', '75_scored',\n",
       "       '100_scored', 'strike_rate_x', 'batting_average', 'notout',\n",
       "       'explosivity_rating', '0_wickets_taken', '1_wickets_taken',\n",
       "       '2_wickets_taken', '3_wickets_taken', '4_wickets_taken',\n",
       "       '5_wickets_taken', '6_wickets_taken', 'bowler_matches_played',\n",
       "       'runs_conceded', 'extras_runs_conceded', 'wickets_taken',\n",
       "       'balls_bowled', '4s_conceded', '6s_conceded', '0s_conceded',\n",
       "       '1s_conceded', '2s_conceded', 'highest_conceded', 'strike_rate_y',\n",
       "       'bowling_average', 'economy', 'total_runs_conceded', 'target',\n",
       "       'current_score', 'balls_left', 'wickets_left', 'runs_left'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\Desktop\\ActualMajor\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Assuming 'df' is your DataFrame\n",
    "columns_to_encode = ['Season', 'BattingTeam', 'BowlingTeam']\n",
    "\n",
    "# Create the OneHotEncoder\n",
    "encoder = OneHotEncoder(drop='first', sparse=False)\n",
    "\n",
    "# Fit and transform the specified columns\n",
    "encoded_columns = encoder.fit_transform(df[columns_to_encode])\n",
    "\n",
    "# Create a DataFrame with the encoded columns\n",
    "df_encoded = pd.DataFrame(encoded_columns, columns=encoder.get_feature_names_out(columns_to_encode))\n",
    "\n",
    "# Concatenate the original DataFrame and the new encoded DataFrame\n",
    "df = pd.concat([df, df_encoded], axis=1)\n",
    "\n",
    "# Drop the original columns that were encoded\n",
    "df.drop(columns=columns_to_encode, inplace=True)\n",
    "\n",
    "# Now, 'df' contains the original data with the One-Hot Encoded columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'innings', 'overs', 'ballnumber', 'batter', 'bowler',\n",
       "       'non-striker', 'extra_type', 'batsman_run', 'extras_run',\n",
       "       ...\n",
       "       'BowlingTeam_Kochi Tuskers Kerala', 'BowlingTeam_Kolkata Knight Riders',\n",
       "       'BowlingTeam_Lucknow Super Giants', 'BowlingTeam_Mumbai Indians',\n",
       "       'BowlingTeam_Pune Warriors', 'BowlingTeam_Punjab Kings',\n",
       "       'BowlingTeam_Rajasthan Royals', 'BowlingTeam_Rising Pune Supergiant',\n",
       "       'BowlingTeam_Royal Challengers Bangalore',\n",
       "       'BowlingTeam_Sunrisers Hyderabad'],\n",
       "      dtype='object', length=121)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Specify the columns to scale\n",
    "columns_to_scale = ['strike_rate_x', 'batting_average', 'strike_rate_y', 'bowling_average', 'economy']\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit and transform the selected columns\n",
    "df[columns_to_scale] = scaler.fit_transform(df[columns_to_scale])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "strike_rate_x      400.0\n",
      "batting_average      inf\n",
      "strike_rate_y        inf\n",
      "bowling_average      inf\n",
      "economy             36.0\n",
      "dtype: float64\n",
      "strike_rate_x      0.0\n",
      "batting_average    0.0\n",
      "strike_rate_y      1.0\n",
      "bowling_average    0.0\n",
      "economy            0.0\n",
      "dtype: float64\n",
      "strike_rate_x      0\n",
      "batting_average    0\n",
      "strike_rate_y      0\n",
      "bowling_average    0\n",
      "economy            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[columns_to_scale].max())\n",
    "print(df[columns_to_scale].min())\n",
    "print(df[columns_to_scale].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace infinite or too large values with the median\n",
    "df[columns_to_scale] = df[columns_to_scale].replace([np.inf, -np.inf], np.nan)\n",
    "df[columns_to_scale] = df[columns_to_scale].fillna(df[columns_to_scale].median())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming df is your preprocessed DataFrame\n",
    "unique_matches = df['ID'].unique()\n",
    "train_matches, test_matches = train_test_split(unique_matches, test_size=0.2, random_state=42)\n",
    "\n",
    "train_data = df[df['ID'].isin(train_matches)]\n",
    "test_data = df[df['ID'].isin(test_matches)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intersection of Match IDs: []\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Find the intersection of unique match IDs\n",
    "intersection_ids = np.intersect1d(train_data['ID'].unique(), test_data['ID'].unique())\n",
    "\n",
    "# Print the intersection\n",
    "print(\"Intersection of Match IDs:\", intersection_ids)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sequence creation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>innings</th>\n",
       "      <th>overs</th>\n",
       "      <th>ballnumber</th>\n",
       "      <th>strike_rate_x</th>\n",
       "      <th>batting_average</th>\n",
       "      <th>strike_rate_y</th>\n",
       "      <th>bowling_average</th>\n",
       "      <th>economy</th>\n",
       "      <th>current_score</th>\n",
       "      <th>balls_left</th>\n",
       "      <th>wickets_left</th>\n",
       "      <th>runs_left</th>\n",
       "      <th>total_run</th>\n",
       "      <th>isWicketDelivery</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.268327</td>\n",
       "      <td>0.288808</td>\n",
       "      <td>0.286548</td>\n",
       "      <td>0.233182</td>\n",
       "      <td>0.204627</td>\n",
       "      <td>1</td>\n",
       "      <td>119</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.268327</td>\n",
       "      <td>0.288808</td>\n",
       "      <td>0.286548</td>\n",
       "      <td>0.233182</td>\n",
       "      <td>0.204627</td>\n",
       "      <td>1</td>\n",
       "      <td>119</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.328585</td>\n",
       "      <td>0.307474</td>\n",
       "      <td>0.286548</td>\n",
       "      <td>0.233182</td>\n",
       "      <td>0.204627</td>\n",
       "      <td>1</td>\n",
       "      <td>118</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.268327</td>\n",
       "      <td>0.288808</td>\n",
       "      <td>0.286548</td>\n",
       "      <td>0.233182</td>\n",
       "      <td>0.204627</td>\n",
       "      <td>1</td>\n",
       "      <td>119</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.328585</td>\n",
       "      <td>0.307474</td>\n",
       "      <td>0.286548</td>\n",
       "      <td>0.233182</td>\n",
       "      <td>0.204627</td>\n",
       "      <td>1</td>\n",
       "      <td>118</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.328585</td>\n",
       "      <td>0.307474</td>\n",
       "      <td>0.286548</td>\n",
       "      <td>0.233182</td>\n",
       "      <td>0.204627</td>\n",
       "      <td>2</td>\n",
       "      <td>117</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.268327</td>\n",
       "      <td>0.288808</td>\n",
       "      <td>0.286548</td>\n",
       "      <td>0.233182</td>\n",
       "      <td>0.204627</td>\n",
       "      <td>1</td>\n",
       "      <td>119</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.328585</td>\n",
       "      <td>0.307474</td>\n",
       "      <td>0.286548</td>\n",
       "      <td>0.233182</td>\n",
       "      <td>0.204627</td>\n",
       "      <td>1</td>\n",
       "      <td>118</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.328585</td>\n",
       "      <td>0.307474</td>\n",
       "      <td>0.286548</td>\n",
       "      <td>0.233182</td>\n",
       "      <td>0.204627</td>\n",
       "      <td>2</td>\n",
       "      <td>117</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.328585</td>\n",
       "      <td>0.307474</td>\n",
       "      <td>0.286548</td>\n",
       "      <td>0.233182</td>\n",
       "      <td>0.204627</td>\n",
       "      <td>2</td>\n",
       "      <td>116</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   innings  overs  ballnumber  strike_rate_x  batting_average  strike_rate_y  \\\n",
       "0        1      0           1       0.268327         0.288808       0.286548   \n",
       "1        1      0           1       0.268327         0.288808       0.286548   \n",
       "2        1      0           2       0.328585         0.307474       0.286548   \n",
       "3        1      0           1       0.268327         0.288808       0.286548   \n",
       "4        1      0           2       0.328585         0.307474       0.286548   \n",
       "5        1      0           3       0.328585         0.307474       0.286548   \n",
       "6        1      0           1       0.268327         0.288808       0.286548   \n",
       "7        1      0           2       0.328585         0.307474       0.286548   \n",
       "8        1      0           3       0.328585         0.307474       0.286548   \n",
       "9        1      0           4       0.328585         0.307474       0.286548   \n",
       "\n",
       "   bowling_average   economy  current_score  balls_left  wickets_left  \\\n",
       "0         0.233182  0.204627              1         119            10   \n",
       "1         0.233182  0.204627              1         119            10   \n",
       "2         0.233182  0.204627              1         118            10   \n",
       "3         0.233182  0.204627              1         119            10   \n",
       "4         0.233182  0.204627              1         118            10   \n",
       "5         0.233182  0.204627              2         117            10   \n",
       "6         0.233182  0.204627              1         119            10   \n",
       "7         0.233182  0.204627              1         118            10   \n",
       "8         0.233182  0.204627              2         117            10   \n",
       "9         0.233182  0.204627              2         116            10   \n",
       "\n",
       "   runs_left  total_run  isWicketDelivery  \n",
       "0          0          1                 0  \n",
       "1          0          1                 0  \n",
       "2          0          0                 0  \n",
       "3          0          1                 0  \n",
       "4          0          0                 0  \n",
       "5          0          1                 0  \n",
       "6          0          1                 0  \n",
       "7          0          0                 0  \n",
       "8          0          1                 0  \n",
       "9          0          0                 0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Create a list to store sequences\n",
    "sequences = []\n",
    "\n",
    "# Iterate over each match\n",
    "for match_id, match_group in train_data.groupby('ID'):\n",
    "    # Iterate over each innings\n",
    "    for inning_id, inning_group in match_group.groupby('innings'):\n",
    "        # Extract the relevant features for the sequence\n",
    "        features = inning_group[['innings', 'overs', 'ballnumber','strike_rate_x', 'batting_average', 'strike_rate_y', 'bowling_average',\n",
    "                                 'economy', 'current_score', 'balls_left', 'wickets_left', 'runs_left','total_run','isWicketDelivery']]\n",
    "\n",
    "        # Create dynamic sequences based on the actual number of balls in each over\n",
    "        for i in range(len(inning_group)):\n",
    "            sequence = features.iloc[:i + 1]  # Adjust the sequence length dynamically\n",
    "            sequences.append(sequence)\n",
    "\n",
    "# Convert the list of sequences to a DataFrame\n",
    "sequences_df = pd.concat(sequences, ignore_index=True)\n",
    "\n",
    "sequences_df.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10835357, 14)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_df = sequences_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10835357, 14)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loader somethign\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CricketDataset(Dataset):\n",
    "    def __init__(self, sequences, targets):\n",
    "        self.sequences = torch.tensor(sequences, dtype=torch.float32)\n",
    "        self.targets = torch.tensor(targets, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.sequences[idx], self.targets[idx]\n",
    "\n",
    "# Assuming seq_df contains your sequences and you have corresponding targets\n",
    "targets_df = seq_df[['total_run', 'isWicketDelivery']]\n",
    "seq_df.drop(['total_run', 'isWicketDelivery'], axis=1, inplace=True)\n",
    "\n",
    "# Convert seq_df and targets_df to numpy arrays\n",
    "sequences_np = seq_df.to_numpy()\n",
    "targets_np = targets_df.to_numpy()\n",
    "\n",
    "# Create DataLoader instances\n",
    "batch_size = 32\n",
    "train_dataset = CricketDataset(sequences_np, targets_np)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10835357, 12), (10835357, 2))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences_np.shape,targets_np.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CricketLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
    "        super(CricketLSTM, self).__init__()\n",
    "\n",
    "        # LSTM layer\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "\n",
    "        # Fully connected layer for total_run prediction\n",
    "        self.fc_total_run = nn.Linear(hidden_size, output_size['total_run'])\n",
    "\n",
    "        # Fully connected layer for isWicketDelivery prediction\n",
    "        self.fc_is_wicket = nn.Linear(hidden_size, output_size['isWicketDelivery'])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through LSTM layer\n",
    "        out, _ = self.lstm(x)\n",
    "\n",
    "        # Only take the output from the final time step\n",
    "        out = out[:, -1, :]\n",
    "\n",
    "        # Predict total_run\n",
    "        total_run_pred = self.fc_total_run(out)\n",
    "\n",
    "        # Predict isWicketDelivery\n",
    "        is_wicket_pred = self.fc_is_wicket(out)\n",
    "        print(\"total_run_pred Shape:\", total_run_pred.shape)\n",
    "        print(\"is_wicket_pred Shape:\", is_wicket_pred.shape)\n",
    "\n",
    "\n",
    "        # Enforce that when isWicketDelivery is 1, total_run must be equal to zero\n",
    "        total_run_pred = total_run_pred * (1 - is_wicket_pred)\n",
    "        print(\"after total_run_pred Shape:\", total_run_pred.shape)\n",
    "        print(\"afdter is_wicket_pred Shape:\", is_wicket_pred.shape)\n",
    "\n",
    "\n",
    "        return total_run_pred, is_wicket_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CricketLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
    "        super(CricketLSTM, self).__init__()\n",
    "\n",
    "        # LSTM layer\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "\n",
    "        # Fully connected layers for total_run and isWicketDelivery\n",
    "        self.fc_total_run = nn.Linear(hidden_size, 1)\n",
    "        self.fc_is_wicket = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through LSTM layer\n",
    "        out, _ = self.lstm(x)\n",
    "\n",
    "        # Only take the output from the final time step\n",
    "        out = out[:, -1, :]\n",
    "\n",
    "        # Separate fully connected layers for total_run and isWicketDelivery\n",
    "        out_total_run = self.fc_total_run(out)\n",
    "        out_is_wicket = self.fc_is_wicket(out)\n",
    "\n",
    "        # Concatenate the predictions\n",
    "        predictions = torch.cat([out_total_run, out_is_wicket], dim=1)\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CricketLSTM(\n",
      "  (lstm): LSTM(12, 60, batch_first=True)\n",
      "  (fc_total_run): Linear(in_features=60, out_features=1, bias=True)\n",
      "  (fc_is_wicket): Linear(in_features=60, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "input_size =  12  # Define input size based on your features\n",
    "hidden_size =  60  # Define hidden size\n",
    "output_size = {'total_run': 1, 'isWicketDelivery': 1}  # Define output size\n",
    "\n",
    "# Instantiate the model\n",
    "model = CricketLSTM(input_size, hidden_size, output_size)\n",
    "\n",
    "# Print the model architecture\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loss function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def custom_loss3(predictions, targets, match_ids):\n",
    "    total_run_pred = predictions[:, 0]  # Assuming the first column is for total_run\n",
    "    is_wicket_pred = predictions[:, 1]  # Assuming the second column is for isWicketDelivery\n",
    "\n",
    "    total_run_actual = targets[:, 0]\n",
    "    is_wicket_actual = targets[:, 1]\n",
    "\n",
    "    # Mean Squared Error (MSE) loss for total_run\n",
    "    total_run_loss = F.mse_loss(total_run_pred, total_run_actual)\n",
    "\n",
    "    # Binary Cross Entropy loss for isWicketDelivery\n",
    "    is_wicket_loss = F.binary_cross_entropy_with_logits(is_wicket_pred, is_wicket_actual)\n",
    "\n",
    "    # Regularization term\n",
    "    regularization_term = torch.abs(total_run_pred.sum(dim=0) - total_run_actual.sum(dim=0)).mean()\n",
    "\n",
    "    # Combined loss\n",
    "    combined_loss = total_run_loss + is_wicket_loss + regularization_term\n",
    "\n",
    "    return combined_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss2(predictions, targets):\n",
    "    total_run_pred = predictions[:, 0]  # Assuming the first column is for total_run\n",
    "    is_wicket_pred = predictions[:, 1]  # Assuming the second column is for isWicketDelivery\n",
    "\n",
    "    total_run_actual = targets[:, 0]\n",
    "    is_wicket_actual = targets[:, 1]\n",
    "\n",
    "    # Mean Squared Error (MSE) loss for total_run\n",
    "    total_run_loss = F.mse_loss(total_run_pred, total_run_actual)\n",
    "\n",
    "    # Binary Cross Entropy loss for isWicketDelivery\n",
    "    is_wicket_loss = F.binary_cross_entropy_with_logits(is_wicket_pred, is_wicket_actual)\n",
    "\n",
    "    # Regularization term\n",
    "    regularization_term = torch.abs(total_run_pred.sum() - total_run_actual.sum())\n",
    "\n",
    "    # Combined loss\n",
    "    combined_loss = total_run_loss + is_wicket_loss + regularization_term\n",
    "\n",
    "    return combined_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def custom_loss(predictions, targets, match_ids, innings):\n",
    "    total_run_pred = predictions[:, 0]  # Assuming the first column is for total_run\n",
    "    is_wicket_pred = predictions[:, 1]  # Assuming the second column is for isWicketDelivery\n",
    "\n",
    "    total_run_actual = targets[:, 0]\n",
    "    is_wicket_actual = targets[:, 1]\n",
    "\n",
    "    # Mean Squared Error (MSE) loss for total_run\n",
    "    total_run_loss = F.mse_loss(total_run_pred, total_run_actual)\n",
    "\n",
    "    # Binary Cross Entropy loss for isWicketDelivery\n",
    "    is_wicket_loss = F.binary_cross_entropy_with_logits(is_wicket_pred, is_wicket_actual)\n",
    "\n",
    "    # Regularization term for each inning within a match\n",
    "    regularization_term = 0.0\n",
    "    unique_matches = match_ids.unique()\n",
    "    \n",
    "    for match_id in unique_matches:\n",
    "        match_indices = (match_ids == match_id).nonzero().view(-1)\n",
    "        innings_in_match = innings[match_indices]\n",
    "        total_run_pred_match = total_run_pred[match_indices]\n",
    "        \n",
    "        # Calculate the regularization term for each inning\n",
    "        for inning in innings_in_match.unique():\n",
    "            inning_indices = (innings_in_match == inning).nonzero().view(-1)\n",
    "            regularization_term += torch.abs(total_run_pred_match[inning_indices].sum(dim=0) - total_run_actual[match_indices][inning_indices].sum(dim=0)).mean()\n",
    "\n",
    "    # Normalize the regularization term by the number of innings\n",
    "    regularization_term /= len(unique_matches)\n",
    "\n",
    "    # Combined loss\n",
    "    combined_loss = total_run_loss + is_wicket_loss + regularization_term\n",
    "\n",
    "    return combined_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "learning_rate = 0.001  # Adjust this value as needed\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_sequences, batch_targets in train_loader:\n",
    "    print(\"Batch Sequences Shape:\", batch_sequences.shape)\n",
    "    print(\"Batch Targets Shape:\", batch_targets.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_sequences\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Calculate the loss\u001b[39;00m\n\u001b[0;32m     15\u001b[0m loss \u001b[38;5;241m=\u001b[39m custom_loss2(predictions, batch_targets)\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\Desktop\\ActualMajor\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\Desktop\\ActualMajor\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[56], line 19\u001b[0m, in \u001b[0;36mCricketLSTM.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     16\u001b[0m out, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlstm(x)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Only take the output from the final time step\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mout\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Predict total_run\u001b[39;00m\n\u001b[0;32m     22\u001b[0m total_run_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc_total_run(out)\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for tensor of dimension 2"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for batch_sequences, batch_targets in train_loader:\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        predictions = model(batch_sequences)\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = custom_loss2(predictions, batch_targets)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # Print the average loss for the epoch\n",
    "    average_loss = total_loss / len(train_loader)\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {average_loss}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ActualMajor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
